{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8433749,"sourceType":"datasetVersion","datasetId":5023018},{"sourceId":188982916,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":25831.70155,"end_time":"2024-07-20T00:28:38.862857","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-19T17:18:07.161307","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikeras","metadata":{"_cell_guid":"777ee72e-8b01-433e-bc23-4861429fa250","_uuid":"84a48732-5e35-423e-b617-25e4d13a67c2","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":17.979427,"end_time":"2024-07-19T17:18:27.860373","exception":false,"start_time":"2024-07-19T17:18:09.880946","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:17.586533Z","iopub.execute_input":"2024-09-15T08:14:17.586983Z","iopub.status.idle":"2024-09-15T08:14:41.005103Z","shell.execute_reply.started":"2024-09-15T08:14:17.586940Z","shell.execute_reply":"2024-09-15T08:14:41.003607Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting scikeras\n  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from scikeras) (3.3.3)\nCollecting scikit-learn>=1.4.2 (from scikeras)\n  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (3.11.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->scikeras) (0.3.2)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (1.14.0)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\nDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\nDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.5.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# IMPORT NECESSARY LIBRARIES\nimport librosa\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport librosa.display\nfrom IPython.display import Audio\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import backend as K\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential, load_model\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_curve\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport os, glob, pickle\nfrom keras.layers import TimeDistributed\nfrom keras.layers import LSTM\nfrom keras.layers import Reshape\nfrom sklearn import datasets, metrics, model_selection, svm\nfrom sklearn.metrics import confusion_matrix\n# from sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.datasets import make_classification\nfrom sklearn.inspection import permutation_importance\nimport IPython.display as ipd  # To play sound in the notebook\nimport os # interface with underlying OS that python is running on\nimport sys\nimport soundfile as sf\nimport warnings\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense\nfrom sklearn.model_selection import GridSearchCV\n# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom scikeras.wrappers import KerasClassifier, KerasRegressor\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.regularizers import l2\nimport seaborn as sns\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nimport soundfile\nseed=7\nnp.random.seed(seed)","metadata":{"_cell_guid":"ef051718-9032-403d-991a-a54bb84737a2","_uuid":"c3080f0c-6f03-4a28-abec-1fc5ceb9f6ec","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":13.470181,"end_time":"2024-07-19T17:18:41.348725","exception":false,"start_time":"2024-07-19T17:18:27.878544","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:41.007518Z","iopub.execute_input":"2024-09-15T08:14:41.007947Z","iopub.status.idle":"2024-09-15T08:14:57.733723Z","shell.execute_reply.started":"2024-09-15T08:14:41.007902Z","shell.execute_reply":"2024-09-15T08:14:57.732474Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_set = \"/kaggle/input/telugu-emotion-speech/telugu/\"\n# Run one example\ndir_list = os.listdir(data_set)\ndir_list[-8:]","metadata":{"_cell_guid":"16bb09ca-2b40-4fb5-bb0d-c98a047b15bb","_uuid":"3ffc8797-8fda-4c82-8e9c-9079fa69aaa0","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.034262,"end_time":"2024-07-19T17:18:41.400437","exception":false,"start_time":"2024-07-19T17:18:41.366175","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:57.735240Z","iopub.execute_input":"2024-09-15T08:14:57.736109Z","iopub.status.idle":"2024-09-15T08:14:57.753235Z","shell.execute_reply.started":"2024-09-15T08:14:57.736027Z","shell.execute_reply":"2024-09-15T08:14:57.752028Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['suprised', 'angry', 'sad', 'nuetral', 'happy']"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize a list to store rows of the DataFrame\ndata = []\nerror_files=['/kaggle/input/telugu-emotion-speech/telugu/sad/S45_SRI_C01_G2_D04_SPKF21_V1_SA4_MMM.wav',\n             '/kaggle/input/telugu-emotion-speech/telugu/sad/S45_SRI_C03_G1_D03_SPKF21_V1_SA4_MMM.wav']\n\n# Loop through each directory and each file within the directory\nfor file_name in dir_list:\n    dir_path = os.path.join(data_set, file_name)\n    sub_dir = os.listdir(dir_path)\n    for dire in sub_dir:\n        file_path = os.path.join(dir_path, dire)\n        emotion = file_name\n        if file_path in error_files:\n            continue\n        data.append([emotion, file_path])\n\n# Create a DataFrame from the data list\ndf = pd.DataFrame(data, columns=['Emotions', 'path'])","metadata":{"_cell_guid":"d5880832-9222-4f60-9142-7937c781ff22","_uuid":"b24553ce-aa59-4670-bff3-130a5a7dd4aa","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.375633,"end_time":"2024-07-19T17:18:41.793185","exception":false,"start_time":"2024-07-19T17:18:41.417552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:57.756578Z","iopub.execute_input":"2024-09-15T08:14:57.757093Z","iopub.status.idle":"2024-09-15T08:14:57.845689Z","shell.execute_reply.started":"2024-09-15T08:14:57.757018Z","shell.execute_reply":"2024-09-15T08:14:57.844135Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# EMO_df.head(5)\ndata_path = df\ndata_path.head(5)\n# data.shape","metadata":{"_cell_guid":"0dddb027-b8a7-49f3-90d7-f3be8a680696","_uuid":"033ebe20-31ab-484a-bc1e-718b32ced56e","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.03509,"end_time":"2024-07-19T17:18:41.845561","exception":false,"start_time":"2024-07-19T17:18:41.810471","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:57.847431Z","iopub.execute_input":"2024-09-15T08:14:57.847946Z","iopub.status.idle":"2024-09-15T08:14:57.870017Z","shell.execute_reply.started":"2024-09-15T08:14:57.847893Z","shell.execute_reply":"2024-09-15T08:14:57.868857Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Emotions                                               path\n0  suprised  /kaggle/input/telugu-emotion-speech/telugu/sup...\n1  suprised  /kaggle/input/telugu-emotion-speech/telugu/sup...\n2  suprised  /kaggle/input/telugu-emotion-speech/telugu/sup...\n3  suprised  /kaggle/input/telugu-emotion-speech/telugu/sup...\n4  suprised  /kaggle/input/telugu-emotion-speech/telugu/sup...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>suprised</td>\n      <td>/kaggle/input/telugu-emotion-speech/telugu/sup...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>suprised</td>\n      <td>/kaggle/input/telugu-emotion-speech/telugu/sup...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>suprised</td>\n      <td>/kaggle/input/telugu-emotion-speech/telugu/sup...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>suprised</td>\n      <td>/kaggle/input/telugu-emotion-speech/telugu/sup...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>suprised</td>\n      <td>/kaggle/input/telugu-emotion-speech/telugu/sup...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming data_path is a DataFrame with an 'emotion' column (containing text labels)\n\n# Create a label encoder\nle = LabelEncoder()\n\n# Encode the emotion labels\ndata_path['emotion_encoded'] = le.fit_transform(data_path['Emotions'])\n\n# Create the countplot using the encoded emotion column\nplt.title('Count of Emotions', size=16)\nsns.countplot(x=\"Emotions\", data=data_path)  # Use \"x\" for the category variable\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\n\n# Remove top and right spines, keep bottom and left for reference\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.show()","metadata":{"_cell_guid":"bbe27ad2-b246-46c8-9d72-8575b4e7e764","_uuid":"cfd94225-1a22-4999-8a40-f7a3d8a8d35f","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.343149,"end_time":"2024-07-19T17:18:42.317428","exception":false,"start_time":"2024-07-19T17:18:41.974279","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:57.871564Z","iopub.execute_input":"2024-09-15T08:14:57.872033Z","iopub.status.idle":"2024-09-15T08:14:58.181732Z","shell.execute_reply.started":"2024-09-15T08:14:57.871977Z","shell.execute_reply":"2024-09-15T08:14:58.180529Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAj8AAAHNCAYAAADxHhq4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7k0lEQVR4nO3deZyN9f//8ecZZjMrEzPUYIgM2UmYrMNYsn8SKYMiZWmSRIstEhUiEdWgT9o+RZ8+oqyjxGQbSzFFSGVmbDNjydDM+/eHn/PtNDOY/Yzrcb/dzu3mvN/v6329rnOdc+bpOte5js0YYwQAAGARLkVdAAAAQGEi/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/ACFaM2aNRo4cKCqV68uX19fubu7q3z58mrXrp1mzZqlEydOFHWJxU50dLQaNWokLy8v2Ww22Ww2HTly5LrLXR17vdvGjRsLfBsK0tXtAPB/ShZ1AYAVnDx5Un379tXatWslSZUrV1br1q3l5eWlhIQEfffdd1q7dq3Gjx+vtWvXqkmTJkVccc5MnDhRkyZN0oQJEzRx4sRCW+/KlSs1aNAgeXh4KDw8XAEBAZIkb2/vG54jIiJCQUFB2fZfq6+otWrVSjExMdqwYYNatWpV1OUAxQbhByhgKSkpCgsLU3x8vGrUqKGFCxfqnnvucRiTlpamJUuWaMKECTp+/HgRVVr8fPLJJ5KkOXPmaPDgwbmaY+zYsTd1cNi/f39RlwA4HcIPUMBGjBih+Ph4Va5cWZs3b1aZMmUyjXF3d9eQIUPUrVs3JScnF36RxdSvv/4qSapWrVoRV+K8atSoUdQlAM7HACgwhw4dMiVKlDCSzGeffZbreT744APTpk0bU7p0aePm5mYqVqxoBg4caOLj47McL8lc6+XdsmVLI8ls2LAh2/Zdu3aZHj16mICAAOPm5mZCQ0PNq6++ajIyMrJcV1a3yMjIG97G8+fPm2nTppn69esbb29v4+npaWrWrGmee+45c/r0aYexkZGReV7n1fH/fAyu5fDhw0aSqVSpkklPTzevv/66qV27tvH09DRBQUHm0UcfNadOnTLGGHPx4kUzefJkc8cddxgPDw9Tvnx5M3LkSHPu3Lls57/R/bxhw4ZrPu7R0dGZtjMrp06dMuPGjTM1a9Y0np6extvb2zRo0MBMnz7dXLhwIdP4q+tt2bKluXTpknn55ZdNzZo1jYeHhylTpozp0aOH+fHHH7Nc1/bt203v3r3NrbfealxdXY2Pj48JCQkxPXv2NCtWrLjeQw/kK8IPUIBef/11I8n4+/ubv/76K8fLZ2RkmP79+xtJpmTJkqZNmzamT58+pnr16kaSKVWqlFm1alWm5fIafsaOHWsPPH369DEtW7a0h7gnnnjCYZnIyEhTt25dI8nUrVvXREZG2m+LFi26oe08deqUqVevnpFkfH19TdeuXU2vXr3MLbfcYiSZkJAQc/jwYfv4RYsWmcjISBMYGGgkmYiIiByvM6/hp2/fvsbT09N06NDBdO/e3ZQrV85IMvXr1zfnzp0zYWFh9m259957jZ+fn5FkOnbsmGnenO7n/fv3Z7v9kZGR5ptvvsm0nf906NAhU6lSJSPJlC1b1vTq1ct07drV+Pj4GEmmQYMGmULn1fDTrFkzEx4ebkqVKmU6dOhgevXqZYKDg+3P9b/vK2OMWbt2rXF1dbU/R/71r3+ZHj16mLvuusu4u7ubbt263fA+APID4QcoQA899JCRZNq0aZOr5efPn28kmVtuucXs2rXL3p6RkWEmTJhg/2OTlJTksFxew48ks2DBAoe+devWGZvNZkqUKGGOHTvm0He1lgkTJuRqO++//34jyTRp0sScPHnS3n727FnTsWNH+x/cG92OG5GX8CPJVK1a1Rw5csTed/LkSVOtWjUjydSuXdvcddddDtvyyy+/mNKlSxtJ5ttvv3WYN7f7+Ua2P7vnQpMmTYwk07VrV4ejUUlJSaZBgwZGknnggQcclvn7Eaf69eub48eP2/v+/PNPExERYSSZIUOGOCzXunVrI8n8+9//zlRHcnKy2bJlS7b1AwWB8AMUoA4dOhhJpk+fPrlavmrVqkaSmTNnTqa+jIwMU6dOHSPJTJ061aEvr+GnZ8+eWS53dXuWLl3q0J6X8HP06FHj4uJibDab2b17d6b+3377zXh4eBhJZvPmzTe0HTfiWh8bXb35+fk5LPP38LNy5cpMc86cOdNIMjabzezduzdT/4gRI4wkM2nSJIf23O7n3Iafb775xn5EKSEhIdMy27dvN5KMi4uLQ9C9Gn5sNpuJi4vLtNzWrVuNJFOlShWH9po1axpJmY4kAUWF6/wATuq3337ToUOHJEmRkZGZ+m02mwYOHChJ2rBhQ76uu0uXLlm2h4aGSpJ+//33fFvXpk2blJGRofr166tOnTqZ+m+99VZFRERIyv/tlK581T0yMjLL2wMPPJDlMiVLllT79u0ztV898bpixYq68847s+3/448/7G1FsZ+vXruoQ4cOCgwMzNTfsGFD1a1bVxkZGYqJicnUX7FiRdWtWzdTe3bPj7vuukuS1K9fP3377bf666+/8roJQJ7wbS+gAJUtW1aSlJSUlONlr/4BCQgIkK+vb5Zjqlat6jA2v1SsWDHL9qt1XLx4Md/WdbX2kJCQbMcU1HZKufuqe/ny5VWyZOa3z6vXF8ru8fPx8ZHk+PgVxX6+0cd89+7dWa7zes+PtLQ0h/Zp06Zpz549WrVqlVatWiVPT081aNBArVq1Ur9+/eyhCSgsHPkBClDDhg0lSTt37lR6enoRV/N/MjIyrtnv4sJbw7Vc7/G52R+/nG5fUFCQtm/frg0bNui5555TkyZNtHPnTk2dOlW1atXS9OnTC6hSIGs39ysUKGL33nuvXFxclJycrP/+9785WvbWW2+VJJ06dUqpqalZjvnll18cxl7l6uoqSTp79myWyx09ejRHtRSkq7Vf3ZasZLedN4O87Oe8rrMwH3ObzaZWrVppypQp2rBhg06fPq358+fLZrPp2WeftX/0BxQGwg9QgKpWraq+fftKkp566imdPn36muOTkpIUHx8vSbrtttvsH3csXrw401hjjL29devWDn1X/2BldXXfPXv26NixYznajutxc3OTpFydy9GiRQu5uLgoLi5Ou3fvztR//PhxrV69WlLm7bwZ5GU/5/Zxv/ox3+rVq5WYmJipf9euXYqLi5OLi4tatGiRo7lvlIeHh4YOHao6deooIyNDe/bsKZD1AFkh/AAFbO7cubr99tt1+PBhhYWF6dtvv8005tKlS3r33XdVv359h8AyevRoSdKLL77oEAyMMZoyZYri4uLk7++f6acdwsPDJUmTJk1yOP/iyJEjioyMlDEmX7fxtttukyT98MMPOV62YsWKuu+++2SM0aOPPqpTp07Z+86fP68hQ4bo4sWLatasmZo1a5ZvNTuT3O7n3D7uYWFhatKkif788089+uijunDhgr3v5MmTevTRRyVJffr0UXBwcK626e9effVV+9W4/+7AgQP6+eefJUmVKlXK83qAG8UJz0ABK126tDZv3qz7779fGzdu1D333KOQkBDVqVNHpUqVUmJior7//nudO3dOvr6+qlChgn3ZRx99VN99953ee+89NWrUSC1btlS5cuW0c+dOxcfHy9PTU8uWLbOfWH3Vs88+q//85z/68ssvVb16dTVu3FgnTpzQtm3b1Lx5czVr1kzfffddvm1jRESEvLy8tGLFCoWFhalatWoqUaKEmjdvbv+m0rXMmzdPBw4cUGxsrKpWrarWrVurZMmSiomJ0YkTJxQSEqL3338/3+r9u5dffjnLIy5XPfDAA1l+sys/5XY/9+rVS9HR0RozZozWrl2rcuXKyWazadCgQdcNisuWLVObNm30+eefKyQkRC1atNDly5e1YcMGpaamqkGDBnrjjTfyZfumTJmip59+WjVq1FBoaKg8PT31xx9/2L/51b9/fzVo0CBf1gXckKL8nj1gNatWrTL9+/c3t99+u/H29jaurq4mKCjItGvXzsyePdv+0wj/tGzZMtOqVSvj7+9vXF1dTXBwsBkwYIA5cOBAtuv68ccfTc+ePU3p0qWNu7u7ueOOO8yUKVPMpUuXbujnLbJyrev5bNq0yYSHh5vSpUsbFxeXXP+8Rb169UypUqWMh4eHCQ0NNc8++2y214cp6Ov8SDKzZs2yL/P3Kzxn5e8//5CV6Ojoaz4uudnPixYtMg0aNDClSpXK9c9bhIaGGg8PD1OqVClTv3598/LLL1/35y2yk9X6/v3vf5uBAweaO++805QpU8a4u7ubSpUqmY4dO5rly5dn+skUoKDZjMnn498AAABOjHN+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+smCMUWpqar5fBRcAABQ9wk8Wzp49Kz8/v2x/FBIAABRfhB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGAphB8AAGApJYu6AABAwYlp0bKoSyjWWm6KKeoSUAA48gMAACyF8AMAACyF8AMAACyF8AMAACyF8AMAACzFqcLPpk2b1KVLF1WoUEE2m00rVqxw6DfGaPz48Spfvrw8PT0VHh6un3/+2WHM6dOn1a9fP/n6+srf318PP/ywzp07V4hbAQAAnJlThZ/z58+rbt26mjdvXpb9M2bM0Jw5c7RgwQLFxsbKy8tLERERunjxon1Mv3799MMPP2jNmjX63//+p02bNmnIkCGFtQkAAMDJ2YwxpqiLyIrNZtPy5cvVvXt3SVeO+lSoUEFPPfWURo8eLUlKSUlRYGCgFi9erD59+mj//v2qWbOmtm3bpkaNGkmSVq9erU6dOum3335ThQoVbmjdqamp8vPzU0pKinx9fQtk+wCgMHCdn7zhOj83J6c68nMthw8fVkJCgsLDw+1tfn5+atKkibZs2SJJ2rJli/z9/e3BR5LCw8Pl4uKi2NjYbOdOS0tTamqqww0AANycik34SUhIkCQFBgY6tAcGBtr7EhISVK5cOYf+kiVLqkyZMvYxWZk2bZr8/Pzst+Dg4HyuHgAAOItiE34K0rhx45SSkmK/HTt2rKhLAgAABaTYhJ+goCBJUmJiokN7YmKivS8oKEhJSUkO/X/99ZdOnz5tH5MVd3d3+fr6OtwAAMDNqdiEn5CQEAUFBWndunX2ttTUVMXGxqpp06aSpKZNmyo5OVk7duywj1m/fr0yMjLUpEmTQq8ZAAA4H6f6Vfdz587p4MGD9vuHDx9WXFycypQpo4oVKyoqKkpTpkxRtWrVFBISohdeeEEVKlSwfyMsNDRUHTp00ODBg7VgwQJdvnxZw4cPV58+fW74m14AAODm5lThZ/v27WrdurX9/qhRoyRJkZGRWrx4scaMGaPz589ryJAhSk5OVlhYmFavXi0PDw/7Mu+//76GDx+utm3bysXFRb169dKcOXMKfVsAAIBzctrr/BQlrvMD4GbBdX7yhuv83JyKzTk/AAAA+YHwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALMWpLnII5MWvk2sXdQnFVsXxe4u6BAAoNBz5AQAAlkL4AQAAlkL4AQAAlkL4AQAAlkL4AQAAlsK3vQAAKARvPPVFUZdQrA1/rUu+zcWRHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCmEHwAAYCkli7qA4q7h00uLuoRia8cr/Yu6BACABXHkBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWArhBwAAWEqxCj/p6el64YUXFBISIk9PT1WtWlUvvviijDH2McYYjR8/XuXLl5enp6fCw8P1888/F2HVAADAmRSr8DN9+nTNnz9fb7zxhvbv36/p06drxowZmjt3rn3MjBkzNGfOHC1YsECxsbHy8vJSRESELl68WISVAwAAZ1GyqAvIie+++07dunVT586dJUmVK1fWBx98oO+//17SlaM+s2fP1vPPP69u3bpJkpYuXarAwECtWLFCffr0KbLaAQCAcyhWR36aNWumdevW6aeffpIk7d69W99++606duwoSTp8+LASEhIUHh5uX8bPz09NmjTRli1bsp03LS1NqampDjcAAHBzKlZHfsaOHavU1FTVqFFDJUqUUHp6uqZOnap+/fpJkhISEiRJgYGBDssFBgba+7Iybdo0TZo0qeAKBwAATqNYHfn5+OOP9f7772vZsmXauXOnlixZoldffVVLlizJ07zjxo1TSkqK/Xbs2LF8qhgAADibYnXk5+mnn9bYsWPt5+7Url1bR48e1bRp0xQZGamgoCBJUmJiosqXL29fLjExUfXq1ct2Xnd3d7m7uxdo7QAAwDkUqyM/Fy5ckIuLY8klSpRQRkaGJCkkJERBQUFat26dvT81NVWxsbFq2rRpodYKAACcU7E68tOlSxdNnTpVFStWVK1atbRr1y7NnDlTgwYNkiTZbDZFRUVpypQpqlatmkJCQvTCCy+oQoUK6t69e9EWDwAAnEKxCj9z587VCy+8oMcff1xJSUmqUKGCHn30UY0fP94+ZsyYMTp//ryGDBmi5ORkhYWFafXq1fLw8CjCygEAgLMoVuHHx8dHs2fP1uzZs7MdY7PZNHnyZE2ePLnwCgMAAMVGsQo/AIqH5nObF3UJxdbmEZuLugTgplesTngGAADIK8IPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwFMIPAACwlGIXfn7//Xc9+OCDCggIkKenp2rXrq3t27fb+40xGj9+vMqXLy9PT0+Fh4fr559/LsKKAQCAMylW4efMmTNq3ry5XF1dtWrVKv3444967bXXVLp0afuYGTNmaM6cOVqwYIFiY2Pl5eWliIgIXbx4sQgrBwAAzqJkUReQE9OnT1dwcLCio6PtbSEhIfZ/G2M0e/ZsPf/88+rWrZskaenSpQoMDNSKFSvUp0+fQq8ZAAA4l1wf+WnTpo3WrVuXbf+GDRvUpk2b3E6fpf/+979q1KiR7rvvPpUrV07169fXokWL7P2HDx9WQkKCwsPD7W1+fn5q0qSJtmzZkq+1AACA4inX4Wfjxo1KTEzMtj8pKUkxMTG5nT5Lv/zyi+bPn69q1arpq6++0mOPPaaRI0dqyZIlkqSEhARJUmBgoMNygYGB9r6spKWlKTU11eEGAABuTnn62Mtms2Xbd/DgQfn4+ORl+kwyMjLUqFEjvfTSS5Kk+vXra9++fVqwYIEiIyNzPe+0adM0adKk/CoTAAA4sRyFnyVLltiPskjSlClTHD52uio5OVl79uxRp06d8l7h35QvX141a9Z0aAsNDdWnn34qSQoKCpIkJSYmqnz58vYxiYmJqlevXrbzjhs3TqNGjbLfT01NVXBwcD5WDgAAnEWOws+FCxd04sQJ+/2zZ8/KxcXxkzObzSYvLy8NHTpU48ePz58q/7/mzZsrPj7eoe2nn35SpUqVJF05+TkoKEjr1q2zh53U1FTFxsbqsccey3Zed3d3ubu752utAADAOeUo/Dz22GP2EBESEqLXX39dXbt2LZDCsvLkk0+qWbNmeumll9S7d299//33WrhwoRYuXCjpSvCKiorSlClTVK1aNYWEhOiFF15QhQoV1L1790KrEwAAOK9cn/Nz+PDh/KzjhjRu3FjLly/XuHHjNHnyZIWEhGj27Nnq16+ffcyYMWN0/vx5DRkyRMnJyQoLC9Pq1avl4eFR6PUCAADnk+fr/Jw9e1ZHjx7VmTNnZIzJ1N+iRYu8rsLBvffeq3vvvTfbfpvNpsmTJ2vy5Mn5ul4AAHBzyHX4OXnypEaMGKFPP/1U6enpmfqNMbLZbFn2AQAAFJVch58hQ4boiy++0MiRI3XPPfc4/MQEAACAs8p1+Pn666/15JNPasaMGflZDwAAQIHK9RWeS5UqpcqVK+djKQAAAAUv1+HnwQcf1PLly/OzFgAAgAKX64+9/vWvfykmJkYdOnTQkCFDFBwcrBIlSmQa16BBgzwVCAAAkJ9yHX7CwsLs/16zZk2mfr7tBQAAnFGuw090dHR+1gEAAFAoch1+8vIr6gAAAEUl1yc8AwAAFEe5PvIzaNCg646x2Wx65513crsKAACAfJfr8LN+/XrZbDaHtvT0dB0/flzp6ekqW7asvLy88lwgAABAfsp1+Dly5EiW7ZcvX9Zbb72l2bNnZ/ktMAAAgKKU7+f8uLq6avjw4Wrfvr2GDx+e39MDAADkSYGd8Fy3bl1t2rSpoKYHAADIlQILP2vWrFGpUqUKanoAAIBcyfU5P5MnT86yPTk5WZs2bdLOnTs1duzYXBcGAABQEHIdfiZOnJhle+nSpVW1alUtWLBAgwcPzu30AAAABSLX4ScjIyM/6wAAACgUXOEZAABYSq6P/FwVExOjlStX6ujRo5KkSpUqqXPnzmrZsmWeiwMAAMhvuQ4/ly5dUt++fbVixQoZY+Tv7y/pygnPr732mnr06KEPPvhArq6u+VUrAABAnuX6Y69JkyZp+fLleuqpp3T8+HGdPn1ap0+fVkJCgkaPHq3PPvss22+EAQAAFJVch59ly5YpMjJSM2bMUGBgoL29XLlymj59uvr376/33nsvX4oEAADIL7kOP8ePH1eTJk2y7W/SpIkSEhJyOz0AAECByHX4ue2227Rx48Zs+2NiYnTbbbfldnoAAIACkevwExkZqY8//lhDhw5VfHy80tPTlZGRofj4eD322GP65JNPNGDAgHwsFQAAIO9y/W2vZ599VocOHdLChQu1aNEiubhcyVEZGRkyxigyMlLPPvtsvhUKAACQH3IdfkqUKKHFixdr1KhR+vLLLx2u89OpUyfVqVMn34oEAADILzkKPxcvXlRUVJRq1aqlESNGSJLq1KmTKejMmTNHCxYs0Ouvv851fgAAgFPJ0Tk/Cxcu1OLFi9W5c+drjuvcubPeffddvf3223kqDgAAIL/lKPx8/PHH6tWrl6pUqXLNcVWrVtV9992nDz74IE/FAQAA5LcchZ+9e/cqLCzshsY2a9ZMe/bsyVVRAAAABSVH4efSpUtyc3O7obFubm5KS0vLVVEAAAAFJUfhp0KFCtq3b98Njd23b58qVKiQq6IAAAAKSo7CT3h4uJYuXaqkpKRrjktKStLSpUvVrl27PBUHAACQ33IUfp555hldvHhRbdq0UWxsbJZjYmNj1bZtW128eFFPP/10vhQJAACQX3J0nZ8qVaro448/Vt++fdWsWTNVqVJFtWvXlo+Pj86ePat9+/bp0KFDKlWqlD788ENVrVq1oOoGAADIlRxf4blz587as2ePpk+frv/9739asWKFva9ChQoaPHiwxowZc92vwwMAABSFXP28ReXKlTV//nzNnz9fZ8+eVWpqqnx9feXj45Pf9QEAAOSrXP+211U+Pj6EHgAAUGzk6IRnAACA4o7wAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALIXwAwAALKVYh5+XX35ZNptNUVFR9raLFy9q2LBhCggIkLe3t3r16qXExMSiKxIAADiVYht+tm3bprfeekt16tRxaH/yySf1xRdf6JNPPlFMTIz++OMP9ezZs4iqBAAAzqZYhp9z586pX79+WrRokUqXLm1vT0lJ0TvvvKOZM2eqTZs2atiwoaKjo/Xdd99p69atRVgxAABwFsUy/AwbNkydO3dWeHi4Q/uOHTt0+fJlh/YaNWqoYsWK2rJlS7bzpaWlKTU11eEGAABuTiWLuoCc+vDDD7Vz505t27YtU19CQoLc3Nzk7+/v0B4YGKiEhIRs55w2bZomTZqU36UCAAAnVKyO/Bw7dkxPPPGE3n//fXl4eOTbvOPGjVNKSor9duzYsXybGwAAOJdiFX527NihpKQkNWjQQCVLllTJkiUVExOjOXPmqGTJkgoMDNSlS5eUnJzssFxiYqKCgoKyndfd3V2+vr4ONwAAcHMqVh97tW3bVnv37nVoGzhwoGrUqKFnnnlGwcHBcnV11bp169SrVy9JUnx8vH799Vc1bdq0KEoGAABOpliFHx8fH915550ObV5eXgoICLC3P/zwwxo1apTKlCkjX19fjRgxQk2bNtXdd99dFCUDAAAnU6zCz42YNWuWXFxc1KtXL6WlpSkiIkJvvvlmUZcFAACcRLEPPxs3bnS47+HhoXnz5mnevHlFUxAAAHBqxeqEZwAAgLwi/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEsh/AAAAEspVuFn2rRpaty4sXx8fFSuXDl1795d8fHxDmMuXryoYcOGKSAgQN7e3urVq5cSExOLqGIAAOBsilX4iYmJ0bBhw7R161atWbNGly9fVvv27XX+/Hn7mCeffFJffPGFPvnkE8XExOiPP/5Qz549i7BqAADgTEoWdQE5sXr1aof7ixcvVrly5bRjxw61aNFCKSkpeuedd7Rs2TK1adNGkhQdHa3Q0FBt3bpVd999d1GUDQAAnEixOvLzTykpKZKkMmXKSJJ27Nihy5cvKzw83D6mRo0aqlixorZs2ZLtPGlpaUpNTXW4AQCAm1OxDT8ZGRmKiopS8+bNdeedd0qSEhIS5ObmJn9/f4exgYGBSkhIyHauadOmyc/Pz34LDg4uyNIBAEARKrbhZ9iwYdq3b58+/PDDPM81btw4paSk2G/Hjh3LhwoBAIAzKlbn/Fw1fPhw/e9//9OmTZt022232duDgoJ06dIlJScnOxz9SUxMVFBQULbzubu7y93dvSBLBgAATqJYHfkxxmj48OFavny51q9fr5CQEIf+hg0bytXVVevWrbO3xcfH69dff1XTpk0Lu1wAAOCEitWRn2HDhmnZsmX6/PPP5ePjYz+Px8/PT56envLz89PDDz+sUaNGqUyZMvL19dWIESPUtGlTvukFAAAkFbPwM3/+fElSq1atHNqjo6M1YMAASdKsWbPk4uKiXr16KS0tTREREXrzzTcLuVIAAOCsilX4McZcd4yHh4fmzZunefPmFUJFAACguClW5/wAAADkFeEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYCuEHAABYyk0bfubNm6fKlSvLw8NDTZo00ffff1/UJQEAACdwU4afjz76SKNGjdKECRO0c+dO1a1bVxEREUpKSirq0gAAQBG7KcPPzJkzNXjwYA0cOFA1a9bUggULVKpUKb377rtFXRoAAChiN134uXTpknbs2KHw8HB7m4uLi8LDw7Vly5YirAwAADiDkkVdQH47efKk0tPTFRgY6NAeGBioAwcOZLlMWlqa0tLS7PdTUlIkSampqdddX3ran3mo1tpu5PHNibMX0/N1PivJ733x159/5et8VpLf++L8X+yLvMjP/fFn2oV8m8uKcrIvfHx8ZLPZsu2/6cJPbkybNk2TJk3K1B4cHFwE1ViH39yhRV0CrprmV9QV4P/ze4Z94VT82B/OYsy8Gx+bkpIiX1/fbPtvuvBzyy23qESJEkpMTHRoT0xMVFBQUJbLjBs3TqNGjbLfz8jI0OnTpxUQEHDN5OjMUlNTFRwcrGPHjl3zCYCCx75wLuwP58G+cB43277w8fG5Zv9NF37c3NzUsGFDrVu3Tt27d5d0JcysW7dOw4cPz3IZd3d3ubu7O7T5+/sXcKWFw9fX96Z4It8M2BfOhf3hPNgXzsMq++KmCz+SNGrUKEVGRqpRo0a66667NHv2bJ0/f14DBw4s6tIAAEARuynDz/33368TJ05o/PjxSkhIUL169bR69epMJ0EDAADruSnDjyQNHz4824+5rMDd3V0TJkzI9HEeCh/7wrmwP5wH+8J5WG1f2IwxpqiLAAAAKCw33UUOAQAAroXwAwAALIXwAwAALIXwYwEbN26UzWZTcnJyga2jVatWioqKKrD5gcJms9m0YsWKoi4DuVC5cmXNnj27qMsocLzv5h7hxwKaNWum48ePy4/LtANwQvwRR2Ej/NzkLl++LDc3NwUFBRXbn+qwmkuXLhV1CYDTMcboL36kFfmE8FPI/vOf/6h27dry9PRUQECAwsPDdf78+Sz/59O9e3cNGDDAfr9y5cp68cUX1bdvX3l5eenWW2/VvHmOv/Rms9k0f/58de3aVV5eXpo6dWqmj72OHj2qLl26qHTp0vLy8lKtWrX05Zdf2ufYt2+fOnbsKG9vbwUGBuqhhx7SyZMn7f3nz59X//795e3trfLly+u1117L98fJWaxevVphYWHy9/dXQECA7r33Xh06dEiSdOTIEdlsNn322Wdq3bq1SpUqpbp162rLli0OcyxatEjBwcEqVaqUevTooZkzZzr8fMrEiRNVr149vf322woJCZGHh4eWLl2qgIAApaWlOczVvXt3PfTQQwW+3cVRdq+tbdu2qV27drrlllvk5+enli1baufOnQ7L/vzzz2rRooU8PDxUs2ZNrVmzpoi2wvm0atVKI0eO1JgxY1SmTBkFBQVp4sSJkv7vNRAXF2cfn5ycLJvNpo0bN9rbrvWeMmDAAMXExOj111+XzWaTzWbTkSNH7O9bq1atUsOGDeXu7q5vv/1Whw4dUrdu3RQYGChvb281btxYa9euLcRHxLlkZGRkuW8kaebMmapdu7a8vLwUHBysxx9/XOfOnbP3L168WP7+/lqxYoWqVasmDw8PRURE6NixY/YxV9+f3nrrLfv7WO/evZWSkiJJ2rRpk1xdXZWQkOBQV1RUlO65556C3fg8IPwUouPHj6tv374aNGiQ9u/fr40bN6pnz57KyaWWXnnlFdWtW1e7du3S2LFj9cQTT2R6o544caJ69OihvXv3atCgQZnmGDZsmNLS0rRp0ybt3btX06dPl7e3t6Qrb1xt2rRR/fr1tX37dq1evVqJiYnq3bu3ffmnn35aMTEx+vzzz/X1119r48aNmf6Y3CzOnz+vUaNGafv27Vq3bp1cXFzUo0cPZWRk2Mc899xzGj16tOLi4lS9enX17dvX/j/UzZs3a+jQoXriiScUFxendu3aaerUqZnWc/DgQX366af67LPPFBcXp/vuu0/p6en673//ax+TlJSklStXZrlPre5ar62zZ88qMjJS3377rbZu3apq1aqpU6dOOnv2rKQrfzx69uwpNzc3xcbGasGCBXrmmWeKeIucy5IlS+Tl5aXY2FjNmDFDkydPvuGAeL33lNdff11NmzbV4MGDdfz4cR0/flzBwcH25ceOHauXX35Z+/fvV506dXTu3Dl16tRJ69at065du9ShQwd16dJFv/76a4Fsu7O71r5xcXHRnDlz9MMPP2jJkiVav369xowZ47D8hQsXNHXqVC1dulSbN29WcnKy+vTp4zDm4MGD+vjjj/XFF19o9erV2rVrlx5//HFJUosWLVSlShW999579vGXL1/W+++/79zvVQaFZseOHUaSOXLkSKa+li1bmieeeMKhrVu3biYyMtJ+v1KlSqZDhw4OY+6//37TsWNH+31JJioqymHMhg0bjCRz5swZY4wxtWvXNhMnTsyyxhdffNG0b9/eoe3YsWNGkomPjzdnz541bm5u5uOPP7b3nzp1ynh6emaq/2Z04sQJI8ns3bvXHD582Egyb7/9tr3/hx9+MJLM/v37jTFX9k/nzp0d5ujXr5/x8/Oz358wYYJxdXU1SUlJDuMee+wxh3372muvmSpVqpiMjIwC2LLi7VqvrX9KT083Pj4+5osvvjDGGPPVV1+ZkiVLmt9//90+ZtWqVUaSWb58eUGVXGy0bNnShIWFObQ1btzYPPPMM/bXwK5du+x9Z86cMZLMhg0bjDHXf0+5uo5/vn9cfd9asWLFdWusVauWmTt3rv1+pUqVzKxZs258I4upa+2brHzyyScmICDAfj86OtpIMlu3brW37d+/30gysbGxxpgr708lSpQwv/32m33MqlWrjIuLizl+/Lgxxpjp06eb0NBQe/+nn35qvL29zblz5/K+kQWEIz+FqG7dumrbtq1q166t++67T4sWLdKZM2dyNEfTpk0z3d+/f79DW6NGja45x8iRIzVlyhQ1b95cEyZM0J49e+x9u3fv1oYNG+Tt7W2/1ahRQ5J06NAhHTp0SJcuXVKTJk3sy5QpU0Z33HFHjrajuPj555/Vt29fValSRb6+vqpcubIkOfwvs06dOvZ/ly9fXtKVozSSFB8fr7vuusthzn/el6RKlSqpbNmyDm2DBw/W119/rd9//13SlUPUAwYM4NytLFzrtZWYmKjBgwerWrVq8vPzk6+vr86dO2ffh/v371dwcLAqVKhgn++frzOr+/tzXLryPL/6HL+e672nXM8/38/OnTun0aNHKzQ0VP7+/vL29tb+/fste+TnWvtm7dq1atu2rW699Vb5+PjooYce0qlTp3ThwgX7+JIlS6px48b2+zVq1JC/v7/D35WKFSvq1ltvtd9v2rSpMjIyFB8fL+nKR5cHDx7U1q1bJV15r+rdu7e8vLzyf4PzCeGnEJUoUUJr1qzRqlWrVLNmTc2dO1d33HGHDh8+LBcXl0wff12+fDlX67neE+6RRx7RL7/8ooceekh79+5Vo0aNNHfuXElX3li6dOmiuLg4h9vVcyKspkuXLjp9+rQWLVqk2NhYxcbGSnI8KdnV1dX+76vB5O8fi92IrPZZ/fr1VbduXS1dulQ7duzQDz/84HAOGP7PtV5bkZGRiouL0+uvv67vvvtOcXFxCggI4MTyHPj7c1y68jzPyMiQi8uVPyF/f+/65/tWXt9T/vnaGD16tJYvX66XXnpJ33zzjeLi4lS7dm3L7s/s9s2RI0d07733qk6dOvr000+1Y8cO+zmi+f1YlStXTl26dFF0dLQSExO1atUq5/7IS4SfQmez2dS8eXNNmjRJu3btkpubm5YvX66yZcvq+PHj9nHp6enat29fpuWvJuu/3w8NDc1xHcHBwRo6dKg+++wzPfXUU1q0aJEkqUGDBvrhhx9UuXJl3X777Q43Ly8vVa1aVa6urvYQIElnzpzRTz/9lOManN2pU6cUHx+v559/Xm3btlVoaGiOj9Tdcccd2rZtm0PbP+9fyyOPPKLFixcrOjpa4eHhDudCwFF2r63Nmzdr5MiR6tSpk2rVqiV3d3eHE/hDQ0N17Ngxh9ffP19nyNrVo5V/f+z+fvKzdP33FElyc3NTenr6Da1z8+bNGjBggHr06KHatWsrKChIR44cyZftuZns2LFDGRkZeu2113T33XerevXq+uOPPzKN++uvv7R9+3b7/fj4eCUnJzv8Xfn1118dlt26datcXFwcjvg/8sgj+uijj7Rw4UJVrVpVzZs3L6Atyx+En0IUGxurl156Sdu3b9evv/6qzz77TCdOnFBoaKjatGmjlStXauXKlTpw4IAee+yxLC9KuHnzZs2YMUM//fST5s2bp08++URPPPFEjuqIiorSV199pcOHD2vnzp3asGGD/Yk+bNgwnT59Wn379tW2bdt06NAhffXVVxo4cKDS09Pl7e2thx9+WE8//bTWr1+vffv2acCAAfb/Ad5MSpcurYCAAC1cuFAHDx7U+vXrNWrUqBzNMWLECH355ZeaOXOmfv75Z7311ltatWrVDX909cADD+i3337TokWLnP5/UkXpWq+tatWq6b333tP+/fsVGxurfv36ydPT075seHi4qlevrsjISO3evVvffPONnnvuuSLcmuLD09NTd999t/2E5JiYGD3//PMOY673niJd+SZrbGysjhw5opMnT17zyGm1atXsXwzYvXu3HnjggRwfabWC22+/XZcvX9bcuXP1yy+/6L333tOCBQsyjXN1ddWIESMUGxurHTt2aMCAAbr77rsdPp738PBweH2MHDlSvXv3VlBQkH1MRESEfH19NWXKFA0cOLBQtjEvbr6/WE7M19dXmzZtUqdOnVS9enU9//zzeu2119SxY0cNGjRIkZGR6t+/v1q2bKkqVaqodevWmeZ46qmntH37dtWvX19TpkzRzJkzFRERkaM60tPTNWzYMIWGhqpDhw6qXr263nzzTUlShQoVtHnzZqWnp6t9+/aqXbu2oqKi5O/vbw84r7zyiu655x516dJF4eHhCgsLU8OGDfP+ADkZFxcXffjhh9qxY4fuvPNOPfnkk3rllVdyNEfz5s21YMECzZw5U3Xr1tXq1av15JNPysPD44aW9/PzU69eveTt7a3u3bvnYius4VqvrXfeeUdnzpxRgwYN9NBDD2nkyJEqV66cfVkXFxctX75cf/75p+666y498sgjWX4jD1l799139ddff6lhw4aKiorSlClTHPpv5D1l9OjRKlGihGrWrKmyZcte8/ydmTNnqnTp0mrWrJm6dOmiiIgINWjQoEC3sTiqW7euZs6cqenTp+vOO+/U+++/r2nTpmUaV6pUKT3zzDN64IEH1Lx5c3l7e+ujjz5yGHP77berZ8+e6tSpk9q3b686derY/2Zc5eLiogEDBig9PV39+/cv0G3LDzbzzxNN4LQqV66sqKgoroRazA0ePFgHDhzQN998c0Pj27Ztq1q1amnOnDkFXBkAK1m8eLGioqKu+dNHEydO1IoVKzJ9nJmVhx9+WCdOnHC4RIezKlnUBQA3u1dffVXt2rWTl5eXVq1apSVLlmT6X1NWzpw5o40bN2rjxo03NB4AikJKSor27t2rZcuWFYvgIxF+gAL3/fffa8aMGTp79qyqVKmiOXPm6JFHHrnucvXr19eZM2c0ffr0m/ZSAgCKv27duun777/X0KFD1a5du6Iu54bwsRcAALAUTngGAACWQvgBAACWQvgBAACWQvgBAACWQvgBAElHjhyRzWbT4sWLi7oUAAWM8AOgQC1evFg2my3bW2H/jtayZcs0e/bsQl0nAOfCdX4AFIrJkycrJCQkU/vtt99eqHUsW7ZM+/bty3Sl9EqVKunPP//M9CvZAG4+hB8AhaJjx45q1KhRUZeRLZvNdsO/uQageONjLwBF7ur5Nq+++qrmzZunKlWqqFSpUmrfvr2OHTsmY4xefPFF3XbbbfL09FS3bt10+vTpTPO8+eabqlWrltzd3VWhQgUNGzbM4XeLWrVqpZUrV+ro0aP2j90qV67sUMM/z/lZv3697rnnHnl5ecnf31/dunXT/v37HcZMnDhRNptNBw8e1IABA+Tv7y8/Pz8NHDhQFy5ccBi7Zs0ahYWFyd/fX97e3rrjjjv07LPP5svjCODGcOQHQKFISUnRyZMnHdpsNpsCAgLs999//31dunRJI0aM0OnTpzVjxgz17t1bbdq00caNG/XMM8/o4MGDmjt3rkaPHq13333XvuzEiRM1adIkhYeH67HHHlN8fLzmz5+vbdu2afPmzXJ1ddVzzz2nlJQU/fbbb5o1a5YkydvbO9ua165dq44dO6pKlSqaOHGi/vzzT82dO1fNmzfXzp077cHpqt69eyskJETTpk3Tzp079fbbb6tcuXKaPn26JOmHH37Qvffeqzp16mjy5Mlyd3fXwYMHtXnz5rw+vABywgBAAYqOjjaSsry5u7sbY4w5fPiwkWTKli1rkpOT7cuOGzfOSDJ169Y1ly9ftrf37dvXuLm5mYsXLxpjjElKSjJubm6mffv2Jj093T7ujTfeMJLMu+++a2/r3LmzqVSpUqY6r9YQHR1tb6tXr54pV66cOXXqlL1t9+7dxsXFxfTv39/eNmHCBCPJDBo0yGHOHj16mICAAPv9WbNmGUnmxIkTN/rwASgAfOwFoFDMmzdPa9ascbitWrXKYcx9990nPz8/+/0mTZpIkh588EGVLFnSof3SpUv6/fffJV05QnPp0iVFRUXJxeX/3tYGDx4sX19frVy5Msf1Hj9+XHFxcRowYIDKlCljb69Tp47atWunL7/8MtMyQ4cOdbh/zz336NSpU0pNTZUk+fv7S5I+//xzZWRk5LgmAPmDj70AFIq77rrruic8V6xY0eH+1SAUHBycZfuZM2ckSUePHpUk3XHHHQ7j3NzcVKVKFXt/TmQ3pySFhobqq6++0vnz5+Xl5ZVt/aVLl7bX6evrq/vvv19vv/22HnnkEY0dO1Zt27ZVz5499a9//cshtAEoWLzaADiNEiVK5KjdGFOQ5eTY9er09PTUpk2btHbtWj300EPas2eP7r//frVr107p6emFWSpgaYQfAMVepUqVJEnx8fEO7ZcuXdLhw4ft/dKVk6zzMqckHThwQLfccovDUZ8b5eLiorZt22rmzJn68ccfNXXqVK1fv14bNmzI8VwAcofwA6DYCw8Pl5ubm+bMmeNwNOidd95RSkqKOnfubG/z8vJSSkrKdecsX7686tWrpyVLljh8XX7fvn36+uuv1alTpxzXmdXX8+vVqydJSktLy/F8AHKHc34AFIpVq1bpwIEDmdqbNWuW5/NdypYtq3HjxmnSpEnq0KGDunbtqvj4eL355ptq3LixHnzwQfvYhg0b6qOPPtKoUaPUuHFjeXt7q0uXLlnO+8orr6hjx45q2rSpHn74YftX3f38/DRx4sQc1zl58mRt2rRJnTt3VqVKlZSUlKQ333xTt912m8LCwnK7+QByiPADoFCMHz8+y/bo6Gi1atUqz/NPnDhRZcuW1RtvvKEnn3xSZcqU0ZAhQ/TSSy85/GTF448/rri4OEVHR2vWrFmqVKlStuEnPDxcq1ev1oQJEzR+/Hi5urqqZcuWmj59epY/1XE9Xbt21ZEjR/Tuu+/q5MmTuuWWW9SyZUtNmjTJ4VtuAAqWzTjbGYMAAAAFiHN+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApRB+AACApfw/VczX8N76evAAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"def create_waveplot(data, sr, e):\n    plt.figure(figsize=(10, 3))\n    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()\n\ndef create_spectrogram(data, sr, e):\n    # stft function converts the data into short term fourier transform\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(12, 3))\n    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n    plt.colorbar()","metadata":{"_cell_guid":"d33d7840-fb92-447c-a387-38f855b5c29d","_uuid":"1c0abc78-f6bb-4a58-bb6d-1d468ab946e7","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.028011,"end_time":"2024-07-19T17:18:42.364041","exception":false,"start_time":"2024-07-19T17:18:42.336030","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:58.183551Z","iopub.execute_input":"2024-09-15T08:14:58.184028Z","iopub.status.idle":"2024-09-15T08:14:58.193518Z","shell.execute_reply.started":"2024-09-15T08:14:58.183975Z","shell.execute_reply":"2024-09-15T08:14:58.192124Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef noise2(data):\n    noise_amp = 0.025*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(data, rate=0.8):\n    return librosa.effects.time_stretch(y=data,rate=rate)\n\ndef shift(data):\n    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n    return np.roll(data, shift_range)\n\ndef pitch(data, sampling_rate, pitch_factor=0.7):\n    return librosa.effects.pitch_shift(y=data,sr=sampling_rate,n_steps=pitch_factor)\n\ndef pitch2(data, sampling_rate, pitch_factor=0.6):\n    return librosa.effects.pitch_shift(y=data,sr=sampling_rate,n_steps=pitch_factor)\n# taking any example and checking for techniques.\npath = np.array(data_path.path)[1]\ndata, sample_rate = librosa.load(path)","metadata":{"_cell_guid":"0632d8fe-41a7-4d4c-9d25-228fc5fe03c1","_uuid":"e90bd6c6-ffac-4359-b14d-2c84baaba5c8","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.062571,"end_time":"2024-07-19T17:18:56.251217","exception":false,"start_time":"2024-07-19T17:18:56.188646","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:14:58.195145Z","iopub.execute_input":"2024-09-15T08:14:58.195638Z","iopub.status.idle":"2024-09-15T08:15:16.817962Z","shell.execute_reply.started":"2024-09-15T08:14:58.195585Z","shell.execute_reply":"2024-09-15T08:15:16.816713Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def extract_features(data):\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result=np.hstack((result, zcr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate,n_mfcc=13).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n       \n    return result","metadata":{"_cell_guid":"15046f97-689c-4817-b977-1b79ce26db79","_uuid":"471b8a4a-8df9-4b74-96f0-f7e9bbfd1dff","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.040123,"end_time":"2024-07-19T17:18:56.319979","exception":false,"start_time":"2024-07-19T17:18:56.279856","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:15:16.819663Z","iopub.execute_input":"2024-09-15T08:15:16.820689Z","iopub.status.idle":"2024-09-15T08:15:16.831720Z","shell.execute_reply.started":"2024-09-15T08:15:16.820630Z","shell.execute_reply":"2024-09-15T08:15:16.830448Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_features(path):\n    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n    result = np.array([])\n    \n    # without augmentation\n    res1 = extract_features(data)\n    result = np.array(res1)\n    \n    # data with noise\n    noise_data = noise(data)\n    res2 = extract_features(noise_data)\n    result = np.vstack((result, res2)) # stacking vertically\n\n    # data with noise2\n    noise_data2 = noise2(data)\n    res3 = extract_features(noise_data2)\n    result = np.vstack((result, res3)) # stacking vertically\n    \n    # data with stretching and pitching\n    new_data = stretch(data)\n    data_stretch_pitch = pitch(new_data, sample_rate)\n    res3 = extract_features(data_stretch_pitch)\n    result = np.vstack((result, res3)) # stacking vertically\n\n    # data with stretching and pitching\n    new_data1 = stretch(data)\n    data_stretch_pitch = pitch2(new_data1, sample_rate)\n    res4 = extract_features(data_stretch_pitch)\n    result = np.vstack((result, res4)) # stacking vertically\n    return result","metadata":{"_cell_guid":"2b2dfe33-4ad0-4950-83c6-691ac462445c","_uuid":"1f16c8d3-849d-4701-a6b5-78d9b0b2dc21","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.039753,"end_time":"2024-07-19T17:18:56.386996","exception":false,"start_time":"2024-07-19T17:18:56.347243","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:15:16.836640Z","iopub.execute_input":"2024-09-15T08:15:16.837155Z","iopub.status.idle":"2024-09-15T08:15:16.858327Z","shell.execute_reply.started":"2024-09-15T08:15:16.837098Z","shell.execute_reply":"2024-09-15T08:15:16.857155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\nfor path, emotion in zip(df.path, df.Emotions):\n    try:\n        feature = get_features(path)\n        for ele in feature:\n            X.append(ele)\n            # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n            Y.append(emotion)\n    except ValueError as e:\n        print(f\"ValueError encountered for file {path}: {e}\")\n        pass","metadata":{"_cell_guid":"884ab1e7-e6a0-4af9-a5dd-f871626095ba","_uuid":"61e3d9c0-4098-4268-a282-c29266dc9274","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":828.654133,"end_time":"2024-07-19T17:32:45.067859","exception":false,"start_time":"2024-07-19T17:18:56.413726","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:17:07.729413Z","iopub.execute_input":"2024-09-15T08:17:07.729874Z","iopub.status.idle":"2024-09-15T08:20:55.089854Z","shell.execute_reply.started":"2024-09-15T08:17:07.729833Z","shell.execute_reply":"2024-09-15T08:20:55.088474Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"ValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S17_ASH_C08_G1_D05_SPKM06_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S22_FID_C08_G1_D04_SPKM02_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S11_ALA_C10_G1_D04_SPKM05_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S15_FID_CO2_G2_D05_SPKM07_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S96_JAM_C02_G2_D03_SPKM04_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S15_FID_CO2_G1_D05_SPKM07_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_TAG_C18_G3_D03_SPKF02_V2_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S20_FID_C08_G1_D04_SPKM09_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S30_NAA_C04_G2_D03_SPKF13_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S17_ASH_C04_G1_D03_SPKM07_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_TAG_C18_G2_D03_SPKF01_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_TAG_C18_G1_D03_SPKM05_V2_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_TAG_C18_G1_D03_SPKM05_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S17_ASH_C04_G1_D01_SPKM07_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_TAG_C18_G3_D03_SPKF02_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_BIL_CO3_G1_D03_SPKM01_V2_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S46_BBM_C04_G1_D04_SPKF24_V1_SU4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S26_KIC_C25_G1_D04_SPKM11_V1_SU3_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S26_KIC_C15_G1_D06_SPKM11_V1_SU3_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/suprised/S95_BIL_CO3_G1_D03_SPKM01_V1_SU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S48_GEH_C1_G1_D01_SPKF24_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S41_AAA_C12_G1_D01_SPKF13_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S95_MIR_CO7_G1_D02_SPKF02_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S48_KIC_C01_G1_D02_SPKF24_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S95_BIL_CO5_G1_D02_SPKM01_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/nuetral/S19_RAC_C05_G2_D02_SPKF05_V1_NU5_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/happy/S96_KIC_C10_G1_D05_SPKF01_V1_HA4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/happy/S15_FID_CO1_G1_D07_SPKM07_V1_HA4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\nValueError encountered for file /kaggle/input/telugu-emotion-speech/telugu/happy/S40_SUR_C03_G1_D03_SPKF03_V1_HA4_MMM.wav: can't extend empty axis 0 using modes other than 'constant' or 'empty'\n","output_type":"stream"}]},{"cell_type":"code","source":"len(X), len(Y), data_path.path.shape","metadata":{"_cell_guid":"0fb2e30d-5aae-45e7-9258-6c616a51ce3b","_uuid":"3cf00dc7-3a9b-4d03-aa42-f18060ae9664","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.069965,"end_time":"2024-07-19T17:32:45.196040","exception":false,"start_time":"2024-07-19T17:32:45.126075","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:55.092635Z","iopub.execute_input":"2024-09-15T08:20:55.093147Z","iopub.status.idle":"2024-09-15T08:20:55.108682Z","shell.execute_reply.started":"2024-09-15T08:20:55.093087Z","shell.execute_reply":"2024-09-15T08:20:55.106613Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(2135, 2135, (456,))"},"metadata":{}}]},{"cell_type":"code","source":"Features = pd.DataFrame(X)\nFeatures['labels'] = Y\nFeatures.to_csv('features.csv', index=False)\nFeatures.head()","metadata":{"_cell_guid":"fff23337-41ff-4dce-82c6-3e14415d645c","_uuid":"7197ff6b-55cd-4566-8844-48bd7bcf57f3","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":2.907187,"end_time":"2024-07-19T17:32:48.131167","exception":false,"start_time":"2024-07-19T17:32:45.223980","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:55.110179Z","iopub.execute_input":"2024-09-15T08:20:55.110687Z","iopub.status.idle":"2024-09-15T08:20:56.228091Z","shell.execute_reply.started":"2024-09-15T08:20:55.110625Z","shell.execute_reply":"2024-09-15T08:20:56.226833Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6  \\\n0  0.067491  0.596592  0.569726  0.576774  0.563486  0.531433  0.563608   \n1  0.264698  0.645614  0.647948  0.656664  0.670795  0.677870  0.643111   \n2  0.250588  0.639666  0.651367  0.659940  0.655215  0.649597  0.629216   \n3  0.066732  0.599684  0.556568  0.556353  0.560526  0.522981  0.561870   \n4  0.063100  0.617144  0.585113  0.563344  0.568284  0.530103  0.542213   \n\n          7         8         9  ...       146       147       148       149  \\\n0  0.588473  0.643593  0.681061  ...  0.000072  0.000113  0.000195  0.000237   \n1  0.644508  0.693153  0.711862  ...  0.003202  0.003393  0.003401  0.003302   \n2  0.657725  0.704230  0.713820  ...  0.001399  0.001472  0.001546  0.001496   \n3  0.600966  0.654602  0.715803  ...  0.000006  0.000009  0.000018  0.000034   \n4  0.595186  0.650620  0.715020  ...  0.000005  0.000011  0.000019  0.000037   \n\n        150       151       152       153       154    labels  \n0  0.000145  0.000127  0.000157  0.000245  0.000022  suprised  \n1  0.003268  0.003418  0.003447  0.003456  0.003375  suprised  \n2  0.001401  0.001451  0.001556  0.001715  0.001320  suprised  \n3  0.000038  0.000036  0.000021  0.000017  0.000002  suprised  \n4  0.000042  0.000034  0.000023  0.000019  0.000001  suprised  \n\n[5 rows x 156 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>146</th>\n      <th>147</th>\n      <th>148</th>\n      <th>149</th>\n      <th>150</th>\n      <th>151</th>\n      <th>152</th>\n      <th>153</th>\n      <th>154</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.067491</td>\n      <td>0.596592</td>\n      <td>0.569726</td>\n      <td>0.576774</td>\n      <td>0.563486</td>\n      <td>0.531433</td>\n      <td>0.563608</td>\n      <td>0.588473</td>\n      <td>0.643593</td>\n      <td>0.681061</td>\n      <td>...</td>\n      <td>0.000072</td>\n      <td>0.000113</td>\n      <td>0.000195</td>\n      <td>0.000237</td>\n      <td>0.000145</td>\n      <td>0.000127</td>\n      <td>0.000157</td>\n      <td>0.000245</td>\n      <td>0.000022</td>\n      <td>suprised</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.264698</td>\n      <td>0.645614</td>\n      <td>0.647948</td>\n      <td>0.656664</td>\n      <td>0.670795</td>\n      <td>0.677870</td>\n      <td>0.643111</td>\n      <td>0.644508</td>\n      <td>0.693153</td>\n      <td>0.711862</td>\n      <td>...</td>\n      <td>0.003202</td>\n      <td>0.003393</td>\n      <td>0.003401</td>\n      <td>0.003302</td>\n      <td>0.003268</td>\n      <td>0.003418</td>\n      <td>0.003447</td>\n      <td>0.003456</td>\n      <td>0.003375</td>\n      <td>suprised</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.250588</td>\n      <td>0.639666</td>\n      <td>0.651367</td>\n      <td>0.659940</td>\n      <td>0.655215</td>\n      <td>0.649597</td>\n      <td>0.629216</td>\n      <td>0.657725</td>\n      <td>0.704230</td>\n      <td>0.713820</td>\n      <td>...</td>\n      <td>0.001399</td>\n      <td>0.001472</td>\n      <td>0.001546</td>\n      <td>0.001496</td>\n      <td>0.001401</td>\n      <td>0.001451</td>\n      <td>0.001556</td>\n      <td>0.001715</td>\n      <td>0.001320</td>\n      <td>suprised</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066732</td>\n      <td>0.599684</td>\n      <td>0.556568</td>\n      <td>0.556353</td>\n      <td>0.560526</td>\n      <td>0.522981</td>\n      <td>0.561870</td>\n      <td>0.600966</td>\n      <td>0.654602</td>\n      <td>0.715803</td>\n      <td>...</td>\n      <td>0.000006</td>\n      <td>0.000009</td>\n      <td>0.000018</td>\n      <td>0.000034</td>\n      <td>0.000038</td>\n      <td>0.000036</td>\n      <td>0.000021</td>\n      <td>0.000017</td>\n      <td>0.000002</td>\n      <td>suprised</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.063100</td>\n      <td>0.617144</td>\n      <td>0.585113</td>\n      <td>0.563344</td>\n      <td>0.568284</td>\n      <td>0.530103</td>\n      <td>0.542213</td>\n      <td>0.595186</td>\n      <td>0.650620</td>\n      <td>0.715020</td>\n      <td>...</td>\n      <td>0.000005</td>\n      <td>0.000011</td>\n      <td>0.000019</td>\n      <td>0.000037</td>\n      <td>0.000042</td>\n      <td>0.000034</td>\n      <td>0.000023</td>\n      <td>0.000019</td>\n      <td>0.000001</td>\n      <td>suprised</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 156 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nX = Features.iloc[: ,:-1].values\nY = Features['labels'].values\nx_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.20, random_state=0, shuffle=True)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"_cell_guid":"492fa73b-4ba2-4a31-86ad-53480840e876","_uuid":"989e4b0e-275c-4f0d-9bf1-6f495a92b899","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.048762,"end_time":"2024-07-19T17:32:48.208673","exception":false,"start_time":"2024-07-19T17:32:48.159911","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.230669Z","iopub.execute_input":"2024-09-15T08:20:56.231089Z","iopub.status.idle":"2024-09-15T08:20:56.247749Z","shell.execute_reply.started":"2024-09-15T08:20:56.231034Z","shell.execute_reply":"2024-09-15T08:20:56.246285Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((1708, 155), (1708,), (427, 155), (427,))"},"metadata":{}}]},{"cell_type":"code","source":"# NORMALIZE DATA\nmean = np.mean(x_train, axis=0)\nstd = np.std(x_train, axis=0)\nx_train = (x_train - mean)/std\nx_test = (x_test - mean)/std","metadata":{"_cell_guid":"e091c950-0ffe-447e-b77c-3b509d239029","_uuid":"7294f832-9fff-483f-b93b-987967e90126","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.044858,"end_time":"2024-07-19T17:32:48.281164","exception":false,"start_time":"2024-07-19T17:32:48.236306","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.249278Z","iopub.execute_input":"2024-09-15T08:20:56.249746Z","iopub.status.idle":"2024-09-15T08:20:56.259561Z","shell.execute_reply.started":"2024-09-15T08:20:56.249684Z","shell.execute_reply":"2024-09-15T08:20:56.258280Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# TURN DATA INTO ARRAYS FOR KERAS\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test = np.array(x_test)\ny_test = np.array(y_test)","metadata":{"_cell_guid":"8976172b-6b51-4295-a346-d2935c10bf1c","_uuid":"86e3d6f1-2819-4728-888b-f227d5c804f3","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.037241,"end_time":"2024-07-19T17:32:48.390193","exception":false,"start_time":"2024-07-19T17:32:48.352952","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.260893Z","iopub.execute_input":"2024-09-15T08:20:56.261319Z","iopub.status.idle":"2024-09-15T08:20:56.269878Z","shell.execute_reply.started":"2024-09-15T08:20:56.261277Z","shell.execute_reply":"2024-09-15T08:20:56.268726Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# ONE HOT ENCODE THE TARGET\n# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\nlb = LabelEncoder()\ny_train = to_categorical(lb.fit_transform(y_train))\ny_test = to_categorical(lb.fit_transform(y_test))\nprint(y_test[0:10])\n# RESHAPE DATA TO INCLUDE 3D TENSOR \nx_train = x_train[:,:,np.newaxis]\nx_test = x_test[:,:,np.newaxis]\n\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"_cell_guid":"ecc2665e-0d77-405b-bfea-2a7c6f3a1930","_uuid":"744a5d3e-2a08-46ab-a6f7-c7a75a2e2e03","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.041917,"end_time":"2024-07-19T17:32:48.460008","exception":false,"start_time":"2024-07-19T17:32:48.418091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.271436Z","iopub.execute_input":"2024-09-15T08:20:56.271838Z","iopub.status.idle":"2024-09-15T08:20:56.284488Z","shell.execute_reply.started":"2024-09-15T08:20:56.271780Z","shell.execute_reply":"2024-09-15T08:20:56.283020Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[[0. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 1.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0.]\n [1. 0. 0. 0. 0.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0.]]\n(1708, 155, 1)\n(427, 155, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the K-fold Cross Validator\nkfold = KFold(n_splits=4, shuffle=True)\nacc_per_fold = []\nloss_per_fold = []\ninputs = np.concatenate((x_train, x_test), axis=0)\ntargets = np.concatenate((y_train, y_test), axis=0)\ninputs.shape\ntargets.shape","metadata":{"_cell_guid":"abc8b093-8481-4700-a681-5dfbaa20f85d","_uuid":"fc4a3580-41dd-454a-85fe-dd02fbefe8b9","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.039086,"end_time":"2024-07-19T17:32:48.527903","exception":false,"start_time":"2024-07-19T17:32:48.488817","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.285843Z","iopub.execute_input":"2024-09-15T08:20:56.286313Z","iopub.status.idle":"2024-09-15T08:20:56.297560Z","shell.execute_reply.started":"2024-09-15T08:20:56.286260Z","shell.execute_reply":"2024-09-15T08:20:56.296273Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(2135, 5)"},"metadata":{}}]},{"cell_type":"code","source":"import random\n#########################################################################\n### Model average / sum Ensemble\n# Simple sum of all outputs / predictions and argmax across all classes\n########\nfrom keras.models import load_model\nfrom sklearn.metrics import accuracy_score\n\nmodel1 = load_model('/kaggle/input/english-mode-e800/saved_models/model1-ravdess.weights.h5') \nmodel2 = load_model('/kaggle/input/english-mode-e800/saved_models/model2-ravdess.weights.h5')\nmodel3 = load_model('/kaggle/input/english-mode-e800/saved_models/model3-ravdess.weights.h5')\n\nmodels = [model1, model2, model3]\n\npreds = [model.predict(x_test) for model in models]\npreds=np.array(preds)\nsummed = np.sum(preds, axis=0)\n\n# argmax across classes\nensemble_prediction = np.argmax(summed, axis=1)\n\nprediction1 = np.argmax(model1.predict(x_test), axis=1)\nprediction2 = np.argmax(model2.predict(x_test), axis=1)\nprediction3 = np.argmax(model3.predict(x_test), axis=1)\n\naccuracy1 = accuracy_score(np.argmax(y_test, axis=1), prediction1)\naccuracy2 = accuracy_score(np.argmax(y_test, axis=1), prediction2)\naccuracy3 = accuracy_score(np.argmax(y_test, axis=1), prediction3)\nensemble_accuracy = accuracy_score(np.argmax(y_test, axis=1), ensemble_prediction)\n\nprint('Accuracy Score for model1 = ', accuracy1)\nprint('Accuracy Score for model2 = ', accuracy2)\nprint('Accuracy Score for model3 = ', accuracy3)\nprint('Accuracy Score for average ensemble = ', ensemble_accuracy)\n\n########################################\n#Weighted average ensemble\nmodels = [model1, model2, model3]\npreds = [model.predict(x_test) for model in models]\npreds=np.array(preds)\nweights = [0.4, 0.2, 0.4]\n\n#Use tensordot to sum the products of all elements over specified axes.\nweighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\nweighted_ensemble_prediction = np.argmax(weighted_preds, axis=1)\n\nweighted_accuracy = accuracy_score(np.argmax(y_test, axis=1), weighted_ensemble_prediction)\nprint('Weighted average method')\nprint('Accuracy Score for model1 = ', accuracy1)\nprint('Accuracy Score for model2 = ', accuracy2)\nprint('Accuracy Score for model3 = ', accuracy3)\nprint('Accuracy Score for average ensemble = ', ensemble_accuracy)\nprint('Accuracy Score for weighted average ensemble = ', weighted_accuracy)\n\n########################################\n#Grid search for the best combination of w1, w2, w3 that gives maximum acuracy\nmodels = [model1, model2, model3]\npreds1 = [model.predict(x_test) for model in models]\npreds1=np.array(preds1)\n\nimport pandas as pd\ndf = pd.DataFrame([])\n\nfor w1 in range(0, 5):\n    for w2 in range(0,5):\n        for w3 in range(0,5):\n            wts = [w1/10.,w2/10.,w3/10.]\n            wted_preds1 = np.tensordot(preds1, wts, axes=((0),(0)))\n            wted_ensemble_pred = np.argmax(wted_preds1, axis=1)\n            weighted_accuracy = accuracy_score(np.argmax(y_test, axis=1), wted_ensemble_pred)\n            df = pd.concat([df, pd.DataFrame({'wt1':wts[0],'wt2':wts[1],\n                                         'wt3':wts[2], 'acc':weighted_accuracy*100}, index=[0])], ignore_index=True)\n            \nmax_acc_row = df.iloc[df['acc'].idxmax()]\nprint(\"Max accuracy of \", max_acc_row[3], \" obained with w1=\", max_acc_row[0],\n      \" w2=\", max_acc_row[1], \" and w3=\", max_acc_row[2])         \n\n\n\n\n###########################################################################\n### Explore metrics for the ideal weighted ensemble model. \n\nmodels = [model1, model2, model3]\npreds = [model.predict(x_test) for model in models]\npreds=np.array(preds)\nideal_weights = [0.4, 0.1, 0.2] \n\n#Use tensordot to sum the products of all elements over specified axes.\nideal_weighted_preds = np.tensordot(preds, ideal_weights, axes=((0),(0)))\nideal_weighted_ensemble_prediction = np.argmax(ideal_weighted_preds, axis=1)\n\nideal_weighted_accuracy = accuracy_score(np.argmax(y_test, axis=1), ideal_weighted_ensemble_prediction)\n\n\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n#Print confusion matrix\ncm = confusion_matrix(np.argmax(y_test, axis=1), ideal_weighted_ensemble_prediction)\ncm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n\nfig, ax = plt.subplots(figsize=(12,12))\nsns.set(font_scale=1.6)\nsns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n\n\n# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION -SGD-MFCC\ncm = confusion_matrix(np.argmax(y_test, axis=1), ideal_weighted_ensemble_prediction)\nplt.figure(figsize = (9,7))\nplt.rcParams['figure.dpi'] = 125 \ncm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\nax = sns.heatmap(cm, linecolor='white', cmap='Accent', linewidth=1, annot=True, fmt='')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.6, top - 0.6)\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Predicted Classes', size=15)\nplt.ylabel('True Classes', size=15)\nplt.savefig('emo-db-model-2.png')\nplt.show()","metadata":{"_cell_guid":"4f28e105-f2bb-4df4-aac8-bb6ca592b462","_uuid":"f395c6a4-b1a8-40ff-9747-551d49a5cacf","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":39.504926,"end_time":"2024-07-19T23:07:10.581098","exception":false,"start_time":"2024-07-19T23:06:31.076172","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-09-15T08:20:56.299373Z","iopub.execute_input":"2024-09-15T08:20:56.299774Z","iopub.status.idle":"2024-09-15T08:21:21.953182Z","shell.execute_reply.started":"2024-09-15T08:20:56.299733Z","shell.execute_reply":"2024-09-15T08:21:21.951459Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\nAccuracy Score for model1 =  0.1920374707259953\nAccuracy Score for model2 =  0.24355971896955503\nAccuracy Score for model3 =  0.24824355971896955\nAccuracy Score for average ensemble =  0.24121779859484777\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\nWeighted average method\nAccuracy Score for model1 =  0.1920374707259953\nAccuracy Score for model2 =  0.24355971896955503\nAccuracy Score for model3 =  0.24824355971896955\nAccuracy Score for average ensemble =  0.24121779859484777\nAccuracy Score for weighted average ensemble =  0.2459016393442623\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\nMax accuracy of  25.526932084309134  obained with w1= 0.0  w2= 0.3  and w3= 0.4\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#Print confusion matrix\u001b[39;00m\n\u001b[1;32m    100\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), ideal_weighted_ensemble_prediction)\n\u001b[0;32m--> 101\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m    104\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.6\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (8, 8), indices imply (5, 5)"],"ename":"ValueError","evalue":"Shape of passed values is (8, 8), indices imply (5, 5)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}